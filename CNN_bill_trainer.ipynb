{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CNN_net(width, height, channels, n_labels):\n",
    "    input_shape = (width, height, channels)\n",
    "    channel_dim = -1\n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (channels, width, height)\n",
    "        channel_dim = 1\n",
    "    \n",
    "    ## Build the CNN\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=input_shape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=channel_dim))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    # first (and only) set of FC => RELU layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # softmax classifier\n",
    "    model.add(Dense(n_labels))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    # return the constructed network architecture\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-p', '--plot'], dest='plot', nargs=None, const=None, default='plot.png', type=<class 'str'>, choices=None, help='path to output accuracy/loss plot', metavar=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--dataset\", required=True, help=\"path to input dataset (i.e., directory of images)\")\n",
    "ap.add_argument(\"-m\", \"--model\", required=True, help=\"path to output model\")\n",
    "ap.add_argument(\"-l\", \"--labelbin\", required=True, help=\"path to output label binarizer\")\n",
    "ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\", help=\"path to output accuracy/loss plot\")\n",
    "#args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Variabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# batch size, and image dimensions\n",
    "N_EPOCHS = 100\n",
    "INIT_LR = 1e-3\n",
    "N_BATCHES = 32\n",
    "IMAGE_DIMS = (96, 96, 3)\n",
    "#IMAGE_PATH = if not args: [\"dataset\"] else '/Users/rafaelferreirarodrigues/Downloads/Notas'\n",
    "IMAGE_PATH = '/Users/rafaelferreirarodrigues/Downloads/Notas'\n",
    "MODEL_PATH = './'\n",
    "PLOT_PATH = './plot.jpg'\n",
    "SEED = 42\n",
    "\n",
    "# initialize the data and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# grab the image paths and randomly shuffle them\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = sorted(list(paths.list_images(IMAGE_PATH)))\n",
    "random.seed(SEED)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images\n",
    "\n",
    "Load all the images in the format: {image path}/{Class}/{image}.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "    # extract the class label from the image path and update the\n",
    "    # labels list\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100 nova', '100 antiga', '200 ', '200 ', '50 nova']\n"
     ]
    }
   ],
   "source": [
    "print(labels[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data matrix: 137.16MB\n"
     ]
    }
   ],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "print(\"[INFO] data matrix: {:.2f}MB\".format(\n",
    "\tdata.nbytes / (1024 * 1000.0)))\n",
    "# binarize the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "\tlabels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incrase the quantity of samples\n",
    "Increase the number of images because each class has less than 250 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "                         horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "WARNING:tensorflow:From /Users/rafaelferreirarodrigues/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 3.3964 - acc: 0.2126\n",
      "16/16 [==============================] - 20s 1s/step - loss: 2.7275 - acc: 0.3957 - val_loss: 3.3945 - val_acc: 0.2126\n",
      "Epoch 2/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 2.5920 - acc: 0.1417\n",
      "16/16 [==============================] - 17s 1s/step - loss: 1.5045 - acc: 0.5433 - val_loss: 2.5885 - val_acc: 0.1417\n",
      "Epoch 3/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 1.7919 - acc: 0.2205\n",
      "16/16 [==============================] - 17s 1s/step - loss: 1.2883 - acc: 0.5787 - val_loss: 1.7900 - val_acc: 0.2205\n",
      "Epoch 4/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 1.6722 - acc: 0.3780\n",
      "16/16 [==============================] - 17s 1s/step - loss: 1.0943 - acc: 0.6614 - val_loss: 1.6700 - val_acc: 0.3780\n",
      "Epoch 5/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 1.6059 - acc: 0.3071\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.9412 - acc: 0.7126 - val_loss: 1.6054 - val_acc: 0.3071\n",
      "Epoch 6/100\n",
      "127/127 [==============================] - 1s 9ms/sample - loss: 1.7503 - acc: 0.2835\n",
      "16/16 [==============================] - 19s 1s/step - loss: 0.8065 - acc: 0.7480 - val_loss: 1.7494 - val_acc: 0.2835\n",
      "Epoch 7/100\n",
      "127/127 [==============================] - 1s 7ms/sample - loss: 1.6188 - acc: 0.3307\n",
      "16/16 [==============================] - 20s 1s/step - loss: 0.7783 - acc: 0.7323 - val_loss: 1.6179 - val_acc: 0.3307\n",
      "Epoch 8/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 1.5611 - acc: 0.2913\n",
      "16/16 [==============================] - 28s 2s/step - loss: 0.7995 - acc: 0.7362 - val_loss: 1.5606 - val_acc: 0.2913\n",
      "Epoch 9/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 1.4125 - acc: 0.3780\n",
      "16/16 [==============================] - 19s 1s/step - loss: 0.7858 - acc: 0.7402 - val_loss: 1.4122 - val_acc: 0.3780\n",
      "Epoch 10/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 1.4406 - acc: 0.3543\n",
      "16/16 [==============================] - 19s 1s/step - loss: 0.6875 - acc: 0.7618 - val_loss: 1.4405 - val_acc: 0.3543\n",
      "Epoch 11/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 1.2612 - acc: 0.4331\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.6500 - acc: 0.7815 - val_loss: 1.2622 - val_acc: 0.4331\n",
      "Epoch 12/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 1.2494 - acc: 0.3937\n",
      "16/16 [==============================] - 19s 1s/step - loss: 0.6688 - acc: 0.7559 - val_loss: 1.2492 - val_acc: 0.3937\n",
      "Epoch 13/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 1.1440 - acc: 0.5512\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.6163 - acc: 0.7894 - val_loss: 1.1444 - val_acc: 0.5512\n",
      "Epoch 14/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 1.1881 - acc: 0.5354\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.5767 - acc: 0.7992 - val_loss: 1.1892 - val_acc: 0.5354\n",
      "Epoch 15/100\n",
      "127/127 [==============================] - 1s 7ms/sample - loss: 1.1501 - acc: 0.5354\n",
      "16/16 [==============================] - 22s 1s/step - loss: 0.6454 - acc: 0.7756 - val_loss: 1.1523 - val_acc: 0.5354\n",
      "Epoch 16/100\n",
      "127/127 [==============================] - 2s 13ms/sample - loss: 1.3943 - acc: 0.3858\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.5672 - acc: 0.7835 - val_loss: 1.3942 - val_acc: 0.3858\n",
      "Epoch 17/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 1.2592 - acc: 0.4409\n",
      "16/16 [==============================] - 21s 1s/step - loss: 0.5768 - acc: 0.8091 - val_loss: 1.2591 - val_acc: 0.4409\n",
      "Epoch 18/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 1.1786 - acc: 0.4567\n",
      "16/16 [==============================] - 19s 1s/step - loss: 0.5648 - acc: 0.7972 - val_loss: 1.1795 - val_acc: 0.4567\n",
      "Epoch 19/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 1.1034 - acc: 0.4882\n",
      "16/16 [==============================] - 19s 1s/step - loss: 0.5041 - acc: 0.8110 - val_loss: 1.1043 - val_acc: 0.4882\n",
      "Epoch 20/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 0.8777 - acc: 0.7008\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.4566 - acc: 0.8346 - val_loss: 0.8798 - val_acc: 0.7008\n",
      "Epoch 21/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.8721 - acc: 0.6693\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.4808 - acc: 0.8287 - val_loss: 0.8721 - val_acc: 0.6693\n",
      "Epoch 22/100\n",
      "127/127 [==============================] - 1s 7ms/sample - loss: 0.8268 - acc: 0.7638\n",
      "16/16 [==============================] - 19s 1s/step - loss: 0.4811 - acc: 0.8366 - val_loss: 0.8209 - val_acc: 0.7638\n",
      "Epoch 23/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.9498 - acc: 0.6299\n",
      "16/16 [==============================] - 20s 1s/step - loss: 0.5392 - acc: 0.8130 - val_loss: 0.9502 - val_acc: 0.6299\n",
      "Epoch 24/100\n",
      "127/127 [==============================] - 1s 10ms/sample - loss: 1.0669 - acc: 0.5906\n",
      "16/16 [==============================] - 22s 1s/step - loss: 0.5621 - acc: 0.8189 - val_loss: 1.0692 - val_acc: 0.5906\n",
      "Epoch 25/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 0.9063 - acc: 0.6614\n",
      "16/16 [==============================] - 22s 1s/step - loss: 0.4657 - acc: 0.8524 - val_loss: 0.9080 - val_acc: 0.6614\n",
      "Epoch 26/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 0.7318 - acc: 0.7244\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.4764 - acc: 0.8268 - val_loss: 0.7316 - val_acc: 0.7244\n",
      "Epoch 27/100\n",
      "127/127 [==============================] - 1s 8ms/sample - loss: 0.9300 - acc: 0.6929\n",
      "16/16 [==============================] - 22s 1s/step - loss: 0.4611 - acc: 0.8327 - val_loss: 0.9306 - val_acc: 0.6929\n",
      "Epoch 28/100\n",
      "127/127 [==============================] - 1s 8ms/sample - loss: 0.6956 - acc: 0.7480\n",
      "16/16 [==============================] - 24s 2s/step - loss: 0.4230 - acc: 0.8386 - val_loss: 0.6914 - val_acc: 0.7480\n",
      "Epoch 29/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 0.9972 - acc: 0.6850\n",
      "16/16 [==============================] - 19s 1s/step - loss: 0.4196 - acc: 0.8445 - val_loss: 0.9983 - val_acc: 0.6850\n",
      "Epoch 30/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.9674 - acc: 0.6614\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.4170 - acc: 0.8366 - val_loss: 0.9681 - val_acc: 0.6614\n",
      "Epoch 31/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 0.9415 - acc: 0.6850\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.3774 - acc: 0.8602 - val_loss: 0.9433 - val_acc: 0.6850\n",
      "Epoch 32/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 2.3652 - acc: 0.4409\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.4248 - acc: 0.8445 - val_loss: 2.3666 - val_acc: 0.4409\n",
      "Epoch 33/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 2.1899 - acc: 0.5197\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.5495 - acc: 0.8189 - val_loss: 2.1899 - val_acc: 0.5197\n",
      "Epoch 34/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 1.6804 - acc: 0.5118\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.5132 - acc: 0.8406 - val_loss: 1.6827 - val_acc: 0.5118\n",
      "Epoch 35/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.8254 - acc: 0.7638\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.3836 - acc: 0.8445 - val_loss: 0.8256 - val_acc: 0.7638\n",
      "Epoch 36/100\n",
      "127/127 [==============================] - 1s 8ms/sample - loss: 0.7101 - acc: 0.8425\n",
      "16/16 [==============================] - 21s 1s/step - loss: 0.4094 - acc: 0.8583 - val_loss: 0.6883 - val_acc: 0.8425\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 1s 7ms/sample - loss: 0.7844 - acc: 0.7874\n",
      "16/16 [==============================] - 19s 1s/step - loss: 0.4532 - acc: 0.8445 - val_loss: 0.7605 - val_acc: 0.7874\n",
      "Epoch 38/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 0.6906 - acc: 0.8189\n",
      "16/16 [==============================] - 21s 1s/step - loss: 0.3884 - acc: 0.8583 - val_loss: 0.6905 - val_acc: 0.8189\n",
      "Epoch 39/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.6341 - acc: 0.7874\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.4203 - acc: 0.8465 - val_loss: 0.6336 - val_acc: 0.7874\n",
      "Epoch 40/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 0.5563 - acc: 0.8346\n",
      "16/16 [==============================] - 19s 1s/step - loss: 0.3093 - acc: 0.8917 - val_loss: 0.5554 - val_acc: 0.8346\n",
      "Epoch 41/100\n",
      "127/127 [==============================] - 1s 7ms/sample - loss: 0.6370 - acc: 0.7795\n",
      "16/16 [==============================] - 24s 2s/step - loss: 0.3553 - acc: 0.8701 - val_loss: 0.6365 - val_acc: 0.7795\n",
      "Epoch 42/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 0.6684 - acc: 0.7559\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.2948 - acc: 0.8937 - val_loss: 0.6676 - val_acc: 0.7559\n",
      "Epoch 43/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 1.2230 - acc: 0.6929\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.3318 - acc: 0.8839 - val_loss: 1.2237 - val_acc: 0.6929\n",
      "Epoch 44/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.7524 - acc: 0.8189\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.4342 - acc: 0.8406 - val_loss: 0.7524 - val_acc: 0.8189\n",
      "Epoch 45/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.4900 - acc: 0.8740\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.3281 - acc: 0.8819 - val_loss: 0.4897 - val_acc: 0.8740\n",
      "Epoch 46/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.7309 - acc: 0.8110\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.3138 - acc: 0.8878 - val_loss: 0.7314 - val_acc: 0.8110\n",
      "Epoch 47/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.8587 - acc: 0.7480\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.3171 - acc: 0.8740 - val_loss: 0.8596 - val_acc: 0.7480\n",
      "Epoch 48/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 1.5466 - acc: 0.6929\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.2784 - acc: 0.8917 - val_loss: 1.5488 - val_acc: 0.6929\n",
      "Epoch 49/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.7507 - acc: 0.8031\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2943 - acc: 0.8898 - val_loss: 0.7510 - val_acc: 0.8031\n",
      "Epoch 50/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.9634 - acc: 0.7480\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.2352 - acc: 0.9173 - val_loss: 0.9642 - val_acc: 0.7480\n",
      "Epoch 51/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.9052 - acc: 0.7480\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2381 - acc: 0.9252 - val_loss: 0.9066 - val_acc: 0.7480\n",
      "Epoch 52/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.7760 - acc: 0.7638\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2570 - acc: 0.8976 - val_loss: 0.7762 - val_acc: 0.7638\n",
      "Epoch 53/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 0.5968 - acc: 0.8268\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.2879 - acc: 0.9114 - val_loss: 0.5968 - val_acc: 0.8268\n",
      "Epoch 54/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 1.3077 - acc: 0.6929\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.3063 - acc: 0.8957 - val_loss: 1.3069 - val_acc: 0.6929\n",
      "Epoch 55/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 1.1083 - acc: 0.7165\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2502 - acc: 0.9252 - val_loss: 1.1082 - val_acc: 0.7165\n",
      "Epoch 56/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 1.9723 - acc: 0.6772\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2233 - acc: 0.9154 - val_loss: 1.9717 - val_acc: 0.6772\n",
      "Epoch 57/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 1.4471 - acc: 0.6772\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2552 - acc: 0.9114 - val_loss: 1.4158 - val_acc: 0.6772\n",
      "Epoch 58/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.9549 - acc: 0.7559\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2609 - acc: 0.9035 - val_loss: 0.9561 - val_acc: 0.7559\n",
      "Epoch 59/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 1.1115 - acc: 0.7087\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.2072 - acc: 0.9232 - val_loss: 1.1118 - val_acc: 0.7087\n",
      "Epoch 60/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.7590 - acc: 0.8189\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.3138 - acc: 0.8878 - val_loss: 0.7589 - val_acc: 0.8189\n",
      "Epoch 61/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 1.7889 - acc: 0.6299\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2368 - acc: 0.9134 - val_loss: 1.7906 - val_acc: 0.6299\n",
      "Epoch 62/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 2.0297 - acc: 0.6378\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2048 - acc: 0.9232 - val_loss: 2.0285 - val_acc: 0.6378\n",
      "Epoch 63/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 0.7845 - acc: 0.7323\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2711 - acc: 0.8976 - val_loss: 0.7835 - val_acc: 0.7323\n",
      "Epoch 64/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 2.0605 - acc: 0.5984\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2898 - acc: 0.8819 - val_loss: 2.0606 - val_acc: 0.5984\n",
      "Epoch 65/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 1.7551 - acc: 0.6535\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2100 - acc: 0.9173 - val_loss: 1.7565 - val_acc: 0.6535\n",
      "Epoch 66/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 1.4140 - acc: 0.7087\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2400 - acc: 0.9134 - val_loss: 1.4162 - val_acc: 0.7087\n",
      "Epoch 67/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 0.5405 - acc: 0.8268\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2643 - acc: 0.8996 - val_loss: 0.5395 - val_acc: 0.8268\n",
      "Epoch 68/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.7121 - acc: 0.8189\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2739 - acc: 0.8957 - val_loss: 0.7108 - val_acc: 0.8189\n",
      "Epoch 69/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.8208 - acc: 0.7953\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2213 - acc: 0.9213 - val_loss: 0.8202 - val_acc: 0.7953\n",
      "Epoch 70/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.6936 - acc: 0.8346\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2354 - acc: 0.9134 - val_loss: 0.6925 - val_acc: 0.8346\n",
      "Epoch 71/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.8051 - acc: 0.7717\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.2337 - acc: 0.9193 - val_loss: 0.8044 - val_acc: 0.7717\n",
      "Epoch 72/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.8521 - acc: 0.7638\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2825 - acc: 0.9016 - val_loss: 0.8537 - val_acc: 0.7638\n",
      "Epoch 73/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.9627 - acc: 0.7717\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2466 - acc: 0.9075 - val_loss: 0.9631 - val_acc: 0.7717\n",
      "Epoch 74/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.9002 - acc: 0.7323\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2728 - acc: 0.8957 - val_loss: 0.8993 - val_acc: 0.7323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 1.1885 - acc: 0.6929\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.2897 - acc: 0.8839 - val_loss: 1.1877 - val_acc: 0.6929\n",
      "Epoch 76/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 1.4121 - acc: 0.7008\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2597 - acc: 0.8937 - val_loss: 1.3933 - val_acc: 0.7008\n",
      "Epoch 77/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 1.0467 - acc: 0.7480\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2619 - acc: 0.8976 - val_loss: 1.0464 - val_acc: 0.7480\n",
      "Epoch 78/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.6865 - acc: 0.8425\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2173 - acc: 0.9193 - val_loss: 0.6855 - val_acc: 0.8425\n",
      "Epoch 79/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.9006 - acc: 0.7638\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2735 - acc: 0.9055 - val_loss: 0.9004 - val_acc: 0.7638\n",
      "Epoch 80/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 1.0735 - acc: 0.6929\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2153 - acc: 0.9350 - val_loss: 1.0734 - val_acc: 0.6929\n",
      "Epoch 81/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 2.0997 - acc: 0.6142\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2210 - acc: 0.9055 - val_loss: 2.1005 - val_acc: 0.6142\n",
      "Epoch 82/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 0.7169 - acc: 0.8031\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2012 - acc: 0.9193 - val_loss: 0.7157 - val_acc: 0.8031\n",
      "Epoch 83/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 1.2348 - acc: 0.7480\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2353 - acc: 0.9035 - val_loss: 1.2350 - val_acc: 0.7480\n",
      "Epoch 84/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.7207 - acc: 0.8425\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.1923 - acc: 0.9350 - val_loss: 0.7202 - val_acc: 0.8425\n",
      "Epoch 85/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 3.6876 - acc: 0.5906\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2281 - acc: 0.9114 - val_loss: 3.6855 - val_acc: 0.5906\n",
      "Epoch 86/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 3.6780 - acc: 0.5591\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.3072 - acc: 0.9035 - val_loss: 3.6958 - val_acc: 0.5591\n",
      "Epoch 87/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 1.8546 - acc: 0.6850\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2594 - acc: 0.8996 - val_loss: 1.8578 - val_acc: 0.6850\n",
      "Epoch 88/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 1.8881 - acc: 0.5984\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2992 - acc: 0.8937 - val_loss: 1.8891 - val_acc: 0.5984\n",
      "Epoch 89/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 1.6658 - acc: 0.6220\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2566 - acc: 0.9213 - val_loss: 1.6663 - val_acc: 0.6220\n",
      "Epoch 90/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.9772 - acc: 0.7402\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2369 - acc: 0.9094 - val_loss: 0.9768 - val_acc: 0.7402\n",
      "Epoch 91/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.6641 - acc: 0.8110\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.1841 - acc: 0.9331 - val_loss: 0.6632 - val_acc: 0.8110\n",
      "Epoch 92/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.4638 - acc: 0.8583\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2274 - acc: 0.9252 - val_loss: 0.4633 - val_acc: 0.8583\n",
      "Epoch 93/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.8338 - acc: 0.8189\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2280 - acc: 0.9213 - val_loss: 0.8341 - val_acc: 0.8189\n",
      "Epoch 94/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 0.6736 - acc: 0.8189\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2201 - acc: 0.9193 - val_loss: 0.6728 - val_acc: 0.8189\n",
      "Epoch 95/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 1.3224 - acc: 0.7087\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2365 - acc: 0.9094 - val_loss: 1.3243 - val_acc: 0.7087\n",
      "Epoch 96/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 0.9425 - acc: 0.7402\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.1993 - acc: 0.9193 - val_loss: 0.9440 - val_acc: 0.7402\n",
      "Epoch 97/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 0.8037 - acc: 0.8110\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2053 - acc: 0.9272 - val_loss: 0.8036 - val_acc: 0.8110\n",
      "Epoch 98/100\n",
      "127/127 [==============================] - 1s 6ms/sample - loss: 2.1308 - acc: 0.5748\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.2049 - acc: 0.9173 - val_loss: 2.1301 - val_acc: 0.5748\n",
      "Epoch 99/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 2.3362 - acc: 0.5984\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2428 - acc: 0.9055 - val_loss: 2.3368 - val_acc: 0.5984\n",
      "Epoch 100/100\n",
      "127/127 [==============================] - 1s 5ms/sample - loss: 1.6328 - acc: 0.7323\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2702 - acc: 0.8957 - val_loss: 1.6335 - val_acc: 0.7323\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = build_CNN_net(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0], channels=IMAGE_DIMS[2], n_labels=len(lb.classes_))\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / N_EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(\n",
    "    x=aug.flow(trainX, trainY, batch_size=N_BATCHES),\n",
    "    validation_data=(testX, testY),\n",
    "    steps_per_epoch=len(trainX) // N_BATCHES,\n",
    "    epochs=N_EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] serializing network...\n",
      "[INFO] serializing label binarizer...\n"
     ]
    }
   ],
   "source": [
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "#model.save(args[\"model\"], save_format=\"h5\")\n",
    "model.save(MODEL_PATH + 'model.h5')\n",
    "\n",
    "# save the label binarizer to disk\n",
    "print(\"[INFO] serializing label binarizer...\")\n",
    "#f = open(args[\"labelbin\"], \"wb\")\n",
    "f = open(MODEL_PATH +'label.bin', \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"
     ]
    }
   ],
   "source": [
    "print(H.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = N_EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig(PLOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
